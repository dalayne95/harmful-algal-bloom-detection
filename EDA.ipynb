{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import  PIL\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from data_cleaning import *\n",
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images appended!\n",
      "(140, 100)\n",
      "images appended!\n",
      "(160, 237)\n",
      "images appended!\n",
      "(140, 100)\n",
      "images appended!\n",
      "(153, 110)\n",
      "images appended!\n",
      "(140, 100)\n",
      "images appended!\n",
      "(220, 165)\n",
      "\n",
      "\n",
      "The minimumn image size is: 140 x 100! We will rescale to this size\n"
     ]
    }
   ],
   "source": [
    "# this function exists in data-cleaning.py\n",
    "test_algae = \"split/test/algae/*\"\n",
    "test_not_algae = \"split/test/not_algae/*\"\n",
    "get_img_stats(test_algae)\n",
    "get_img_stats(test_not_algae)\n",
    "\n",
    "train_algae = \"split/train/algae/*\"\n",
    "train_not_algae = \"split/train/not_algae/*\"\n",
    "get_img_stats(train_algae)\n",
    "get_img_stats(train_not_algae)\n",
    "\n",
    "val_algae = \"split/validation/algae/*\"\n",
    "val_not_algae = \"split/validation/not_algae/*\"\n",
    "get_img_stats(val_algae)\n",
    "get_img_stats(val_not_algae)\n",
    "print(\"\\n\")\n",
    "print(\"The minimumn image size is: 140 x 100! We will rescale to this size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 228 images belonging to 2 classes.\n",
      "Found 570 images belonging to 2 classes.\n",
      "Found 160 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# reshape the images using Keras \n",
    "\n",
    "# get all the data in the directory split/test (230 images), and reshape them\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory('split/test/', \n",
    "        target_size=(140, 100), batch_size = 230)\n",
    "\n",
    "# get all the data in the directory split/train (570 images), and reshape them\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    'split/train/', \n",
    "    target_size=(140, 100), batch_size=570)\n",
    "\n",
    "# get all the data in the directory split/validation (160 images), and reshape them\n",
    "val_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    'split/validation/', \n",
    "    target_size=(140, 100), batch_size = 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we'll move on to creating the data sets w/ labels \n",
    "train_images, train_labels = next(train_generator)\n",
    "test_images, test_labels = next(test_generator)\n",
    "val_images, val_labels = next(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 570\n",
      "Number of testing samples: 228\n",
      "Number of validation samples: 160\n",
      "train_images shape: (570, 140, 100, 3)\n",
      "train_labels shape: (570, 2)\n",
      "test_images shape: (228, 140, 100, 3)\n",
      "test_labels shape: (228, 2)\n",
      "val_images shape: (160, 140, 100, 3)\n",
      "val_labels shape: (160, 2)\n"
     ]
    }
   ],
   "source": [
    "# lets check our dataset numbers again \n",
    "m_train = train_images.shape[0]\n",
    "num_px = train_images.shape[1]\n",
    "m_test = test_images.shape[0]\n",
    "m_val = val_images.shape[0]\n",
    "\n",
    "print (\"Number of training samples: \" + str(m_train))\n",
    "print (\"Number of testing samples: \" + str(m_test))\n",
    "print (\"Number of validation samples: \" + str(m_val))\n",
    "print (\"train_images shape: \" + str(train_images.shape))\n",
    "print (\"train_labels shape: \" + str(train_labels.shape))\n",
    "print (\"test_images shape: \" + str(test_images.shape))\n",
    "print (\"test_labels shape: \" + str(test_labels.shape))\n",
    "print (\"val_images shape: \" + str(val_images.shape))\n",
    "print (\"val_labels shape: \" + str(val_labels.shape))\n",
    "\n",
    "shuffle = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(570, 42000)\n",
      "(228, 42000)\n",
      "(160, 42000)\n"
     ]
    }
   ],
   "source": [
    "train_img = train_images.reshape(train_images.shape[0], -1)\n",
    "test_img = test_images.reshape(test_images.shape[0], -1)\n",
    "val_img = val_images.reshape(val_images.shape[0], -1)\n",
    "\n",
    "print(train_img.shape)\n",
    "print(test_img.shape)\n",
    "print(val_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(570, 1)\n",
      "(228, 1)\n",
      "(160, 1)\n"
     ]
    }
   ],
   "source": [
    "train_y = np.reshape(train_labels[:,0], (570,1))\n",
    "test_y = np.reshape(test_labels[:,0], (228,1))\n",
    "val_y = np.reshape(val_labels[:,0], (160,1))\n",
    "\n",
    "print(train_y.shape)\n",
    "print(test_y.shape)\n",
    "print(val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
